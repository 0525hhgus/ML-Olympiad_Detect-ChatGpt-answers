{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyN2xAQfswIe6SIVR1XwC2Mg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-EEzvLQAZUK","executionInfo":{"status":"ok","timestamp":1677983434401,"user_tz":-540,"elapsed":9027,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"44dfb0fc-3060-4edc-9ffb-6aee9ee94310"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting autokeras\n","  Downloading autokeras-1.1.0-py3-none-any.whl (148 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-tuner>=1.1.0\n","  Downloading keras_tuner-1.3.0-py3-none-any.whl (167 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from autokeras) (1.3.5)\n","Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from autokeras) (2.11.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from autokeras) (23.0)\n","Collecting keras-nlp>=0.4.0\n","  Downloading keras_nlp-0.4.1-py3-none-any.whl (466 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.8/466.8 KB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from keras-nlp>=0.4.0->autokeras) (1.4.0)\n","Collecting tensorflow-text\n","  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-nlp>=0.4.0->autokeras) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.25.1)\n","Collecting kt-legacy\n","  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (7.9.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (4.5.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (23.1.21)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (15.0.6.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.19.6)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n","Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.11.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n","Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.11.2)\n","Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.11.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.31.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.51.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->autokeras) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->autokeras) (2022.7.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.38.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (3.4.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (0.4.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (2.2.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (2.16.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (1.8.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (4.0.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.7.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.2.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.0.10)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text->keras-nlp>=0.4.0->autokeras) (0.12.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner>=1.1.0->autokeras) (0.8.3)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (6.0.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner>=1.1.0->autokeras) (0.2.6)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (2.1.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (3.2.2)\n","Installing collected packages: kt-legacy, jedi, tensorflow-text, keras-tuner, keras-nlp, autokeras\n","Successfully installed autokeras-1.1.0 jedi-0.18.2 keras-nlp-0.4.1 keras-tuner-1.3.0 kt-legacy-1.0.4 tensorflow-text-2.11.0\n"]}],"source":["!pip install autokeras"]},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","\n","drive.mount('/content/drive')\n","\n","PATH = \"/content/drive/MyDrive/ML-Olympiad/Detect-ChatGpt-answers/\"\n","\n","train = pd.read_csv(PATH+'data/train.csv')\n","test = pd.read_csv(PATH+'data/test.csv')\n","submission = pd.read_csv(PATH+'data/sample_submission.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3sSeQXJqAgfk","executionInfo":{"status":"ok","timestamp":1677983459369,"user_tz":-540,"elapsed":24973,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"e7ca70df-7bbd-48cb-f349-bffa61e39d3a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hypu-qwzAslU","executionInfo":{"status":"ok","timestamp":1677983459370,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## 1. 전처리"],"metadata":{"id":"nRolyZnP_vgF"}},{"cell_type":"code","source":[],"metadata":{"id":"O1zUKRlmA4Ei","executionInfo":{"status":"ok","timestamp":1677983459370,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["train[\"text\"]=train[\"prompt\"]+train[\"answer\"]\n","train=train[[\"text\",\"AI\"]]"],"metadata":{"id":"rOwXsjSlxgXO","executionInfo":{"status":"ok","timestamp":1677983459370,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["test[\"text\"]=test[\"prompt\"]+test[\"answer\"]\n","test=test[\"text\"]"],"metadata":{"id":"m2Y8Kloqxh6-","executionInfo":{"status":"ok","timestamp":1677983459371,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train[\"text\"].isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFmBfwld7vhe","executionInfo":{"status":"ok","timestamp":1677983459371,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"08bf1fe4-968d-4475-d7fe-dde04345dbc3"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["train = train[train[\"text\"].isna()==False]"],"metadata":{"id":"WGwYr0hL7ksA","executionInfo":{"status":"ok","timestamp":1677983459371,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["train[\"AI\"].isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZo8a7lpYpoc","executionInfo":{"status":"ok","timestamp":1677983459371,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"d3452543-ff3a-4ffc-e832-5ac5a4cc2a91"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["train = train[train[\"AI\"].isna()==False]"],"metadata":{"id":"piagTAKWYv6I","executionInfo":{"status":"ok","timestamp":1677983459371,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["test.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCskOvfy7zfD","executionInfo":{"status":"ok","timestamp":1677983459372,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"6f98127d-8afe-4053-85cd-9fcfa1ebab3b"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"O5vFWcU27oHi","executionInfo":{"status":"ok","timestamp":1677983459372,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"02c3acd4-5d9e-4e80-a95a-a7eb3795e97e"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  text   AI\n","0    What is the future of AI?The future of Artific...  1.0\n","1    What is your biggest challenge in your career?...  0.0\n","2    What is the tallest mountain in the world?The ...  1.0\n","3    What are the best 5 super cars?McLaren 720S.\\r...  0.0\n","4    What is deep learning?a type of machine learni...  0.0\n","..                                                 ...  ...\n","743  What is the most important thing in a family?T...  0.0\n","744  What are the best machine learning Models?Line...  0.0\n","745  How can I chop onions without crying?The best ...  0.0\n","746  What is the best way to stay healthy?The best ...  0.0\n","747  Do you think Naruto is overrated?I think Narut...  1.0\n","\n","[746 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-da5a55dc-eba5-4c44-9e3e-7194678bfd72\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>AI</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What is the future of AI?The future of Artific...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What is your biggest challenge in your career?...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What is the tallest mountain in the world?The ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What are the best 5 super cars?McLaren 720S.\\r...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What is deep learning?a type of machine learni...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>743</th>\n","      <td>What is the most important thing in a family?T...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>744</th>\n","      <td>What are the best machine learning Models?Line...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>745</th>\n","      <td>How can I chop onions without crying?The best ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>746</th>\n","      <td>What is the best way to stay healthy?The best ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>747</th>\n","      <td>Do you think Naruto is overrated?I think Narut...</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>746 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da5a55dc-eba5-4c44-9e3e-7194678bfd72')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-da5a55dc-eba5-4c44-9e3e-7194678bfd72 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-da5a55dc-eba5-4c44-9e3e-7194678bfd72');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["!pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yj4XJ7T8D6o","executionInfo":{"status":"ok","timestamp":1677983464462,"user_tz":-540,"elapsed":5099,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"36b315e4-3242-494e-eb8c-e454728edc27"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting emoji\n","  Downloading emoji-2.2.0.tar.gz (240 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=fb8a7df0abc4ee57c54b0b23c54bec0492cca119c1349aede2f6b346cc74931a\n","  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-2.2.0\n"]}]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"XE1Xs7JE7pl5","executionInfo":{"status":"ok","timestamp":1677983464462,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import re\n","def removeHTML(x):\n","    html=re.compile(r'<.*?>')\n","    return html.sub(r'',x)\n","    \n","import emoji\n","def dataPreprocessing(x): \n","    x = x.lower()\n","    x = removeHTML(x)\n","    x = emoji.demojize(x, delimiters=(\" \", \" \"))\n","    x = re.sub(\"@\\w+\", '',x) # removing mentions (@)\n","    x = re.sub(\"'\\d+\", '',x)\n","    x = re.sub(\"\\d+\", '',x)\n","    x = re.sub(r\"[^\\w\\s]\", '',x) # to remove symbols\n","    x = re.sub(\"http\\w+\", '',x)\n","    x = re.sub(\"\\s[a-z]\\s\", '',x)\n","    x = x.strip()\n","    return x"],"metadata":{"id":"ug9bcCUT7-v0","executionInfo":{"status":"ok","timestamp":1677983464462,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["\n","train_text=train[\"text\"].apply(lambda x: dataPreprocessing(x))"],"metadata":{"id":"PBqH8aMx8BU5","executionInfo":{"status":"ok","timestamp":1677983465143,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["test_text=test.apply(lambda x: dataPreprocessing(x))"],"metadata":{"id":"ZVGLymfCZPcF","executionInfo":{"status":"ok","timestamp":1677983465143,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["train_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07YWck3z87M_","executionInfo":{"status":"ok","timestamp":1677983465143,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"13e0f64f-d3c9-4ea6-c64b-c228584c0c8f"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      what is the future of aithe future of artifici...\n","1      what is your biggest challenge in your careerm...\n","2      what is the tallest mountain in the worldthe t...\n","3      what are the best  super carsmclaren\\nferrari ...\n","4      what is deep learninga type of machine learnin...\n","                             ...                        \n","743    what is the most important thing infamilythe m...\n","744    what are the best machine learning modelslinea...\n","745    how canchop onions without cryingthe best thin...\n","746    what is the best way to stay healthythe best w...\n","747    do you think naruto is overratedi think naruto...\n","Name: text, Length: 746, dtype: object"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X = train_text\n","y = train['AI']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"b4iVfyxP8qKV","executionInfo":{"status":"ok","timestamp":1677983465541,"user_tz":-540,"elapsed":403,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(X_train, columns=['text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"ZxHyWrZX8_f9","executionInfo":{"status":"ok","timestamp":1677983465541,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"5bb24148-40f8-4251-f49d-16e53e6384e6"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  text\n","70   what is the name of the unit used to measure p...\n","164  what is the name of the largest underwater cav...\n","712  what is the name of the gas that makes up the ...\n","265  what is the name of the largest underwater cav...\n","250  what is the most important factor in makingdec...\n","..                                                 ...\n","71   what is your biggest strengthmy biggest streng...\n","106  what is the currency of australiaaustralian do...\n","270  what is the best way to stay positivethe best ...\n","435  what is the name of the largest underwater cav...\n","102  what is your opinion on the current state of a...\n","\n","[596 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-8097f37a-a606-4325-a13c-e23566f3cc33\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>70</th>\n","      <td>what is the name of the unit used to measure p...</td>\n","    </tr>\n","    <tr>\n","      <th>164</th>\n","      <td>what is the name of the largest underwater cav...</td>\n","    </tr>\n","    <tr>\n","      <th>712</th>\n","      <td>what is the name of the gas that makes up the ...</td>\n","    </tr>\n","    <tr>\n","      <th>265</th>\n","      <td>what is the name of the largest underwater cav...</td>\n","    </tr>\n","    <tr>\n","      <th>250</th>\n","      <td>what is the most important factor in makingdec...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>what is your biggest strengthmy biggest streng...</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>what is the currency of australiaaustralian do...</td>\n","    </tr>\n","    <tr>\n","      <th>270</th>\n","      <td>what is the best way to stay positivethe best ...</td>\n","    </tr>\n","    <tr>\n","      <th>435</th>\n","      <td>what is the name of the largest underwater cav...</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>what is your opinion on the current state of a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>596 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8097f37a-a606-4325-a13c-e23566f3cc33')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8097f37a-a606-4325-a13c-e23566f3cc33 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8097f37a-a606-4325-a13c-e23566f3cc33');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["pd.DataFrame(y_train, columns=['AI'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"XvKx3L909BkG","executionInfo":{"status":"ok","timestamp":1677983465542,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"0be6e70c-ed2d-4135-f12b-8180491b333d"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      AI\n","70   1.0\n","164  0.0\n","712  0.0\n","265  0.0\n","250  0.0\n","..   ...\n","71   0.0\n","106  0.0\n","270  0.0\n","435  0.0\n","102  1.0\n","\n","[596 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-dd7216a9-08b6-478e-bf16-1bbccf0d709c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AI</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>70</th>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>164</th>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>712</th>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>265</th>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>250</th>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>270</th>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>435</th>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>596 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd7216a9-08b6-478e-bf16-1bbccf0d709c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dd7216a9-08b6-478e-bf16-1bbccf0d709c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dd7216a9-08b6-478e-bf16-1bbccf0d709c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# train_data = pd.concat([pd.DataFrame(X_train, columns=['text']), pd.DataFrame(y_train, columns=['AI'])], axis=1)\n","# train_data"],"metadata":{"id":"9FSGQj2a9C3O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_data = pd.concat([pd.DataFrame(X_test, columns=['text']), pd.DataFrame(y_test, columns=['AI'])], axis=1)\n","# test_data"],"metadata":{"id":"5wMugyNy97Iq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"-F-DlQq9X5Sq","executionInfo":{"status":"ok","timestamp":1677983465542,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# 길이 분포 출력\n","text_len = [len(s.split()) for s in X_train]\n","\n","print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n","print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n","print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n","\n","\n","plt.subplot(1,2,2)\n","plt.boxplot(text_len)\n","plt.title('Text')\n","plt.tight_layout()\n","plt.show()\n","\n","plt.title('Text')\n","plt.hist(text_len, bins=40)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":629},"id":"dEiQ6cdlX5gW","executionInfo":{"status":"ok","timestamp":1677983465966,"user_tz":-540,"elapsed":432,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"c53abe17-44c0-4707-f309-858ef1438acb"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["텍스트의 최소 길이 : 6\n","텍스트의 최대 길이 : 303\n","텍스트의 평균 길이 : 33.89261744966443\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZiklEQVR4nO3debRlZXnn8e+PAnFCESlZDGJBpG1NVMQSdYkGJSqIHbAbFVsRFWU5k8SpUFvpRJfQJo4xKIpaMUZCHCIdnJCAxlbRYpBRBRm0EKEcQHAAgaf/2O/dHi/3Vp2qe8859976ftba6+797n3Oft7aVfXc993vfneqCkmSALaYdACSpIXDpCBJ6pkUJEk9k4IkqWdSkCT1TAqSpJ5JQZLUMylIQ0hy08Bye5LfDGw/exO+b98ka0cRqzQXW046AGkxqKq7T60nuRJ4YVV9eXIRSaNhS0GagyRbJFmV5AdJfpbk5CTbtX3HJ/nUwLHHJTk9yd2AzwM7DbQ2dppUHaRBJgVpbl4BHAz8KbAT8AvgfW3fq4AHJ3lekscCRwCHV9WvgAOAH1fV3dvy4/GHLt2R3UfS3LwYeHlVrQVIcgzwwySHVdWvkxxG1yq4EXjF1HHSQmVSkObmfsBnktw+UHYbsANwdVWdleRy4D7AyZMIUNoYdh9Jc/Mj4ICq2nZguXNVXQ2Q5GXA1sCPgdcOfM7pibUgmRSkuXk/8NYk9wNIsjzJQW39vwBvAZ4DHAa8Nsme7XPXAvdOcs/xhyzNzqQgzc27gVOALyW5Efgm8MgkWwL/BBxXVd+pqkuB1wMfS7J1VX0X+ARweZLrHX2khSK+ZEeSNMWWgiSpZ1KQJPVMCpKknklBktRb1A+vbb/99rVixYpJhyFJi8rZZ5/906paPtO+RZ0UVqxYwZo1ayYdhiQtKkmumm2f3UeSpJ5JQZLUMylIknomBUlSz6QgSeqZFCRJPZOCJKlnUpAk9UwKkqTeon6ieZJWrDp11n1XHnvgGCORpPljS0GS1DMpSJJ6JgVJUs+kIEnqmRQkST1HH81ifaOLJGmpsqUgSeqZFCRJPZOCJKlnUpAk9UwKkqSeSUGS1DMpSJJ6JgVJUm9kSSHJh5Ncl+TCgbK3J/lukvOTfCbJtgP7jk5yWZLvJXnyqOKSJM1ulC2FjwL7Tys7DfiTqnoI8H3gaIAkDwIOBf64feYfkiwbYWySpBmMLClU1VeBn08r+1JV3do2vwns0tYPAk6qqpur6grgMmDvUcUmSZrZJO8pvAD4fFvfGfjRwL61rUySNEYTSQpJ3gDcCnx8Ez57ZJI1SdasW7du/oOTpM3Y2JNCkucBTwWeXVXViq8G7jtw2C6t7A6q6oSqWllVK5cvXz7SWCVpczPWpJBkf+C1wJ9X1a8Hdp0CHJpk6yS7AXsA3xpnbJKkEb5PIckngH2B7ZOsBd5MN9poa+C0JADfrKoXV9VFSU4GLqbrVnpZVd02qtgkSTMbWVKoqmfNUHzieo5/K/DWUcUjSdown2iWJPVMCpKknklBktQzKUiSeiYFSVLPpCBJ6pkUJEk9k4IkqWdSkCT1TAqSpJ5JQZLUMylIknomBUlSz6QgSeqZFCRJPZOCJKlnUpAk9UwKkqSeSUGS1DMpSJJ6JgVJUs+kIEnqmRQkSb2RJYUkH05yXZILB8q2S3Jakkvbz3u18iR5T5LLkpyfZK9RxSVJmt0oWwofBfafVrYKOL2q9gBOb9sABwB7tOVI4PgRxiVJmsXIkkJVfRX4+bTig4DVbX01cPBA+T9W55vAtkl2HFVskqSZjfuewg5VdU1b/wmwQ1vfGfjRwHFrW9kdJDkyyZoka9atWze6SCVpMzSxG81VVUBtwudOqKqVVbVy+fLlI4hMkjZfG0wKSZ6eZJu2/sYkn57DjeBrp7qF2s/rWvnVwH0HjtullUmSxmiYlsL/qqobk+wD/BlwIpt+I/gU4PC2fjjw2YHy57ZRSI8CbhjoZpIkjckwSeG29vNA4ISqOhW404Y+lOQTwDeAByRZm+QI4FjgiUkupUswx7bDPwdcDlwGfBB46UbVQpI0L7Yc4pirk3wAeCJwXJKtGSKZVNWzZtm13wzHFvCyIWKRJI3QMC2FZwBfBJ5cVdcD2wGvGWVQkqTJGOY3/l/T3RDepxXdClw6yqAkSZMxzOijNwOvA45uRVsB/zTKoCRJkzHMPYWnAQ8DzgGoqh9PDVFdzFasOnXSIUjSgjPMPYVbBh80S3K30YYkSZqUYZLCyW300bZJXgR8mW7YqCRpidlg91FV/W2SJwK/BB4AvKmqTht5ZJKksRvmngItCZgIJGmJmzUpJLmRmSesC93zZvcYWVSSpImYNSlU1aIfYSRJ2jhDdR+1WVH3oWs5fK2qzh1pVJKkiRjm4bU30b0l7d7A9sBHk7xx1IFJksZvmJbCs4GHVtVvAZIcC5wHvGWEcUmSJmCY5xR+DNx5YHtrfAGOJC1Jw7QUbgAuSnIa3T2FJwLfSvIegKp65QjjkySN0TBJ4TNtmXLmaEKRJE3aME80rx5HIJKkyRtm9NFTk5yb5OdJfpnkxiS/HEdwkqTxGqb76F3AfwcuaLOlSpKWqGFGH/0IuNCEIElL3zAthdcCn0vyFeDmqcKqesfIopIkTcQwSeGtwE10zyrcabThLA0beqvblcceOKZIJGnjDJMUdqqqP5nPkyb5S+CFdM89XAA8H9gROIluOo2zgcOq6pb5PK8kaf2GuafwuSRPmq8TJtkZeCWwsiWbZcChwHHAO6vq/sAvgCPm65ySpOEMkxReAnwhyW/mcUjqlsBdkmwJ3BW4BngC8Mm2fzVw8BzPIUnaSMM8vDav71WoqquT/C3wQ+A3wJfououur6pb22FrgZ1n+nySI4EjAXbdddf5DE2SNnvDtBRIcq8keyd53NSyqSdMci/gIGA3YCfgbsD+w36+qk6oqpVVtXL58uWbGoYkaQYbbCkkeSFwFLAL3ZTZjwK+Qdfdsyn+DLiiqta17/808Bhg2yRbttbCLjgTqySN3TAthaOARwBXVdXjgYcB18/hnD8EHpXkrkkC7AdcDJwBHNKOORz47BzOIUnaBMMkhd8OvGBn66r6LvCATT1hVZ1Fd0P5HLrhqFsAJwCvA/4qyWV0w1JP3NRzSJI2zTDPKaxNsi3wb8BpSX4BXDWXk1bVm4E3Tyu+HNh7Lt8rSZqbYUYfPa2tHpPkDOCewBdGGpUkaSKGmTr7j5JsPbUJrKB7tkCStMQMc0/hU8BtSe5P1/d/X+CfRxqVJGkihkkKt7dhok8D3ltVr6Gbp0iStMQMkxR+l+RZdMNE/72VbTW6kCRJkzJMUng+8GjgrVV1RZLdgI+NNixJ0iQMM/roYrpZTae2r6Cb0VSStMQMNfeRJGnzYFKQJPVmTQpJPtZ+HjW+cCRJk7S+lsLDk+wEvKBNnb3d4DKuACVJ47O+G83vB04Hdqd7CU4G9lUrlyQtIbO2FKrqPVX1QODDVbV7Ve02sJgQJGkJGmZI6kuSPBR4bCv6alWdP9qwJEmTMMyEeK8EPg7cpy0fT/KKUQcmSRq/Yd6n8ELgkVX1K4Akx9G9jvO9owxMkjR+wzynEOC2ge3b+MObzpKkJWKYlsJHgLOSfKZtH4yvypSkJWmYG83vSHImsE8ren5VnTvSqCRJEzFMS4GqOgc4Z8SxSJImzLmPJEk9k4IkqbfepJBkWZIzxhWMJGmy1psUquo24PYk95zPkybZNsknk3w3ySVJHt0m2jstyaXt573m85ySpA0b5kbzTcAFSU4DfjVVWFWvnP0jG/Ru4AtVdUiSOwF3BV4PnF5VxyZZBawCXjeHc0iSNtIwSeHTbZkXrdXxOOB5AFV1C3BLkoOAfdthq4EzMSlI0lgN85zC6iR3AXatqu/Nwzl3A9YBH2kT7Z0NHAXsUFXXtGN+Auww04eTHAkcCbDrrrvOQziSpCnDTIj334DzgC+07T2TnDKHc24J7AUcX1UPo+uSWjV4QFUV3Tsb7qCqTqiqlVW1cvny5XMIQ5I03TBDUo8B9gauB6iq85jbC3bWAmur6qy2/Um6JHFtkh0B2s/r5nAOSdImGCYp/K6qbphWdvumnrCqfgL8KMkDWtF+wMXAKcDhrexw4LObeg5J0qYZ5kbzRUn+J7AsyR7AK4Gvz/G8r6B7L8OdgMuB59MlqJOTHAFcBTxjjudYsFasOnXWfVcee+AYI5GkPzRMUngF8AbgZuATwBeBv5nLSVsX1MoZdu03l++VJM3NMKOPfg28ob1cp6rqxtGHJUmahGFGHz0iyQXA+XQPsX0nycNHH5okadyG6T46EXhpVf0nQJJ96F6885BRBiZJGr9hRh/dNpUQAKrqa8CtowtJkjQps7YUkuzVVr+S5AN0N5kLeCbdFBSSpCVmfd1Hfzdt+80D6zM+bSxJWtxmTQpV9fhxBiJJmrwN3mhOsi3wXGDF4PFznDpbkrQADTP66HPAN4ELmMP0FpKkhW+YpHDnqvqrkUciSZq4YYakfizJi5Ls2F6ZuV2S7UYemSRp7IZpKdwCvJ1u/qOpUUfF3KbPliQtQMMkhVcB96+qn446GEnSZA3TfXQZ8OtRByJJmrxhWgq/As5Lcgbd9NmAQ1IlaSkaJin8W1skSUvcMO9TWD2OQCRJkzfME81XMMNcR1Xl6CNJWmKG6T4afG3mnYGnAz6nIElL0AZHH1XVzwaWq6vqXYBvl5ekJWiY7qO9Bja3oGs5DNPCkCQtMsP85z74XoVbgSuBZ4wkGknSRA0z+mgk71VIsgxYA1xdVU9NshtwEnBv4GzgsKq6ZRTnliTNbJjuo62B/8Ed36fw13M891HAJcA92vZxwDur6qQk7weOAI6f4zkkSRthmGkuPgscRNd19KuBZZMl2YXuZvWH2naAJwCfbIesBg6eyzkkSRtvmHsKu1TV/vN83ncBrwW2adv3Bq6vqlvb9lpg55k+mORI4EiAXXfddZ7DkqTN2zAtha8nefB8nTDJU4HrqursTfl8VZ1QVSurauXy5cvnKyxJEsO1FPYBnteebL4ZCFBV9ZBNPOdjgD9P8hS6h+HuAbwb2DbJlq21sAtw9SZ+vyRpEw2TFA6YzxNW1dHA0QBJ9gVeXVXPTvKvwCF0I5AOp7uXIUkao2GGpF41jkCA1wEnJXkLcC5w4pjOK0lqJvpkclWdCZzZ1i8H9p5kPJK0uRvmRrMkaTNhUpAk9UwKkqSeSUGS1DMpSJJ6JgVJUs+kIEnqmRQkST2TgiSpZ1KQJPVMCpKknklBktQzKUiSeiYFSVJvolNn645WrDp1vfuvPPbAMUUiaXNkS0GS1DMpSJJ6JgVJUs+kIEnqmRQkST2TgiSpZ1KQJPXGnhSS3DfJGUkuTnJRkqNa+XZJTktyaft5r3HHJkmbu0m0FG4FXlVVDwIeBbwsyYOAVcDpVbUHcHrbliSN0diTQlVdU1XntPUbgUuAnYGDgNXtsNXAweOOTZI2dxO9p5BkBfAw4Cxgh6q6pu36CbDDLJ85MsmaJGvWrVs3nkAlaTMxsaSQ5O7Ap4C/qKpfDu6rqgJqps9V1QlVtbKqVi5fvnwMkUrS5mMiSSHJVnQJ4eNV9elWfG2SHdv+HYHrJhGbJG3OJjH6KMCJwCVV9Y6BXacAh7f1w4HPjjs2SdrcTWLq7McAhwEXJDmvlb0eOBY4OckRwFXAMyYQmyRt1saeFKrqa0Bm2b3fOGORJP0hn2iWJPVMCpKknklBktQzKUiSeiYFSVJvEkNSNUIrVp06674rjz1wjJFIWoxsKUiSerYUFpn1tQQkaa5sKUiSeiYFSVLPpCBJ6pkUJEk9k4IkqWdSkCT1TAqSpJ5JQZLU8+G1zciGHnxzGgxJthQkST1bCuotxZbEUqyTNEq2FCRJPVsKmhdz+Y3c3+alhcOkoKHNZYbWSX1WC4fJf3Gw+0iS1FtwLYUk+wPvBpYBH6qqYycckjSjpfib71Ks02I1qWuxoJJCkmXA+4AnAmuBbyc5paounmxkWqpG2TU1qlejzjVm/2PX+iy07qO9gcuq6vKqugU4CThowjFJ0mYjVTXpGHpJDgH2r6oXtu3DgEdW1csHjjkSOLJtPgD43ga+dnvgpyMId1KWUn2sy8JkXRau+arP/apq+Uw7FlT30TCq6gTghGGPT7KmqlaOMKSxWkr1sS4Lk3VZuMZRn4XWfXQ1cN+B7V1amSRpDBZaUvg2sEeS3ZLcCTgUOGXCMUnSZmNBdR9V1a1JXg58kW5I6oer6qI5fu3QXU2LxFKqj3VZmKzLwjXy+iyoG82SpMlaaN1HkqQJMilIknpLOikk2T/J95JclmTVpOPZWEmuTHJBkvOSrGll2yU5Lcml7ee9Jh3nTJJ8OMl1SS4cKJsx9nTe067T+Un2mlzkM5ulPsckubpdn/OSPGVg39GtPt9L8uTJRD2zJPdNckaSi5NclOSoVr7ors966rLork2SOyf5VpLvtLr871a+W5KzWsz/0gbhkGTrtn1Z279iXgKpqiW50N2o/gGwO3An4DvAgyYd10bW4Upg+2ll/wdY1dZXAcdNOs5ZYn8csBdw4YZiB54CfB4I8CjgrEnHP2R9jgFePcOxD2p/37YGdmt/D5dNug4D8e0I7NXWtwG+32JedNdnPXVZdNem/fneva1vBZzV/rxPBg5t5e8HXtLWXwq8v60fCvzLfMSxlFsKS3XKjIOA1W19NXDw5EKZXVV9Ffj5tOLZYj8I+MfqfBPYNsmOYwl0SLPUZzYHASdV1c1VdQVwGd3fxwWhqq6pqnPa+o3AJcDOLMLrs566zGbBXpv253tT29yqLQU8AfhkK59+Xaau1yeB/ZJkrnEs5aSwM/Cjge21rP8vy0JUwJeSnN2m9wDYoaquaes/AXaYTGibZLbYF/O1ennrUvnwQFfeoqlP63J4GN1vpYv6+kyrCyzCa5NkWZLzgOuA0+haMtdX1a3tkMF4+7q0/TcA955rDEs5KSwF+1TVXsABwMuSPG5wZ3XtxkU5pngxxz7geOCPgD2Ba4C/m2g0GynJ3YFPAX9RVb8c3LfYrs8MdVmU16aqbquqPelmc9gb+K/jjmEpJ4VFP2VGVV3dfl4HfIbuL8m1U0339vO6yUW40WaLfVFeq6q6tv0jvh34IL/vhljw9UmyFd1/oh+vqk+34kV5fWaqy2K+NgBVdT1wBvBouu66qQeNB+Pt69L23xP42VzPvZSTwqKeMiPJ3ZJsM7UOPAm4kK4Oh7fDDgc+O5kIN8lssZ8CPLeNcnkUcMNAN8aCNa1f/Wl01we6+hzaRofsBuwBfGvc8c2m9TufCFxSVe8Y2LXors9sdVmM1ybJ8iTbtvW70L1X5hK65HBIO2z6dZm6XocA/9FaeHMz6Tvuo1zoRk18n65f7g2TjmcjY9+dbpTEd4CLpuKn6zM8HbgU+DKw3aRjnSX+T9A1239H1w96xGyx0426eF+7ThcAKycd/5D1+ViL9/z2D3THgePf0OrzPeCAScc/rS770HUNnQ+c15anLMbrs566LLprAzwEOLfFfCHwpla+O13iugz4V2DrVn7ntn1Z27/7fMThNBeSpN5S7j6SJG0kk4IkqWdSkCT1TAqSpJ5JQZLUMylo0Uhy04aP2ujv3HPaDJrHJHn1HL7v6UkuSXLG/ES4yXFcmWT7ScagxcmkoM3dnnTj2ufLEcCLqurx8/id0tiYFLQoJXlNkm+3Cc+m5p1f0X5L/2Cbj/5L7clQkjyiHXtekrcnubA96f7XwDNb+TPb1z8oyZlJLk/yylnO/6x077q4MMlxrexNdA9TnZjk7dOO3zHJV9t5Lkzy2FZ+fJI1g/Pnt/Irk7ytHb8myV5JvpjkB0le3I7Zt33nqeneDfD+JHf4N53kOenm6T8vyQfapGvLkny0xXJBkr+c4yXRUjHpp/hcXIZdgJvazyfRvcA8dL/Y/Dvd+w5WALcCe7bjTgae09YvBB7d1o+lvRcBeB7w9wPnOAb4Ot18+9vTzSWz1bQ4dgJ+CCwHtgT+Azi47TuTGZ74BV7F759KXwZs09a3Gyg7E3hI276S38+b/066p1y3aee8tpXvC/yW7onXZXSzah4y8PntgQcC/3eqDsA/AM8FHg6cNhDftpO+vi4LY7GloMXoSW05FziHbibJPdq+K6rqvLZ+NrCizSezTVV9o5X/8wa+/9Tq5tv/Kd2kcNOnJ38EcGZVratuyuKP0yWl9fk28PwkxwAPrm7uf4BnJDmn1eWP6V4CM2Vqrq4L6F5sc2NVrQNunpojB/hWde8MuY1uKo59pp13P7oE8O02JfN+dEnkcmD3JO9Nsj/wSyS633KkxSbA26rqA39Q2M2nf/NA0W3AXTbh+6d/x5z/nVTVV9vU5wcCH03yDuA/gVcDj6iqXyT5KN18NtPjuH1aTLcPxDR9nprp2wFWV9XR02NK8lDgycCLgWcAL9jYemnpsaWgxeiLwAvaHPok2TnJfWY7uLppiG9M8shWdOjA7hvpumU2xreAP02yfZJlwLOAr6zvA0nuR9ft80HgQ3Sv9rwH8CvghiQ70L03Y2Pt3WYC3gJ4JvC1aftPBw6Z+vNJ9x7m+7WRSVtU1aeAN7Z4JFsKWnyq6ktJHgh8o5s5mZuA59D9Vj+bI4APJrmd7j/wG1r5GcCq1rXytiHPf02SVe2zoetu2tAU5vsCr0nyuxbvc6vqiiTnAt+le4PW/xvm/NN8G/h74P4tns9Mi/XiJG+ke4PfFnSzvL4M+A3wkYEb03doSWjz5Cyp2iwkuXu199+2/9B3rKqjJhzWnCTZl+7l9E+dcChaQmwpaHNxYJKj6f7OX0U36kjSNLYUJEk9bzRLknomBUlSz6QgSeqZFCRJPZOCJKn3/wFZMX8ROjkuZgAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# 2. 모델링"],"metadata":{"id":"xQZwKieRA4zr"}},{"cell_type":"code","source":[],"metadata":{"id":"759k4ekdwUku"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.datasets import load_files\n","\n","import autokeras as ak"],"metadata":{"id":"vk5B889mBJbi","executionInfo":{"status":"ok","timestamp":1677983469763,"user_tz":-540,"elapsed":3801,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Initialize the text classifier.\n","clf = ak.TextClassifier(\n","    overwrite=True, max_trials=6, objective='val_accuracy', seed=32\n",")  "],"metadata":{"id":"kL4iU2RZA6ju","executionInfo":{"status":"ok","timestamp":1677983469763,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# 모델 저장 경로\n","model_dir = PATH+\"model/autokeras_trial6_230305/\"\n","if not os.path.exists(model_dir):\n","    os.mkdir(model_dir)\n","\n","# 체크포인트 파일 저장 경로\n","checkpoint_path = model_dir+\"checkpoints_model_autokeras_230305.ckpt\""],"metadata":{"id":"hFG2sY8nKexY","executionInfo":{"status":"ok","timestamp":1677983473235,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["callbacks = [\n","tf.keras.callbacks.ModelCheckpoint(\n","    checkpoint_path, save_weights_only=True, \n","    monitor=\"val_accuracy\", mode=\"max\", verbose=1, save_best_only=True\n","), \n","tf.keras.callbacks.ReduceLROnPlateau(\n","    monitor=\"val_accuracy\", factor=0.5, patience=8, min_lr=0.0001\n","),\n","tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode='max', patience=10, verbose=1), # val_acc로 설정했는데 모델마다 먹히는 경우가 다름 -> 버그로 추정?\n","]"],"metadata":{"id":"nMnSzzOtKM0_","executionInfo":{"status":"ok","timestamp":1677983479479,"user_tz":-540,"elapsed":527,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Feed the text classifier with training data.\n","clf.fit(X_train.values, y_train.values, callbacks=callbacks, validation_split=0.2, epochs=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A4fwZG2SBV2G","outputId":"e90f3025-c750-4bf1-e442-089c27a35b98","executionInfo":{"status":"ok","timestamp":1677984971440,"user_tz":-540,"elapsed":1487278,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 6 Complete [00h 03m 47s]\n","val_accuracy: 0.9166666865348816\n","\n","Best val_accuracy So Far: 0.9404761791229248\n","Total elapsed time: 00h 17m 55s\n","Epoch 1/50\n","19/19 [==============================] - ETA: 0s - loss: 0.5940 - accuracy: 0.6997"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 57s 378ms/step - loss: 0.5940 - accuracy: 0.6997 - lr: 2.0000e-05\n","Epoch 2/50\n","19/19 [==============================] - ETA: 0s - loss: 0.4271 - accuracy: 0.8221"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 281ms/step - loss: 0.4271 - accuracy: 0.8221 - lr: 2.0000e-05\n","Epoch 3/50\n","19/19 [==============================] - ETA: 0s - loss: 0.2920 - accuracy: 0.8893"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 280ms/step - loss: 0.2920 - accuracy: 0.8893 - lr: 2.0000e-05\n","Epoch 4/50\n","19/19 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9060"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 287ms/step - loss: 0.2282 - accuracy: 0.9060 - lr: 2.0000e-05\n","Epoch 5/50\n","19/19 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9480"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 283ms/step - loss: 0.1554 - accuracy: 0.9480 - lr: 2.0000e-05\n","Epoch 6/50\n","19/19 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9597"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 283ms/step - loss: 0.1123 - accuracy: 0.9597 - lr: 2.0000e-05\n","Epoch 7/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9698"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 287ms/step - loss: 0.0786 - accuracy: 0.9698 - lr: 2.0000e-05\n","Epoch 8/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9664"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 285ms/step - loss: 0.0860 - accuracy: 0.9664 - lr: 2.0000e-05\n","Epoch 9/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9765"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 286ms/step - loss: 0.0577 - accuracy: 0.9765 - lr: 2.0000e-05\n","Epoch 10/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9664"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 284ms/step - loss: 0.0665 - accuracy: 0.9664 - lr: 2.0000e-05\n","Epoch 11/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9799"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 282ms/step - loss: 0.0587 - accuracy: 0.9799 - lr: 2.0000e-05\n","Epoch 12/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9748"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 285ms/step - loss: 0.0563 - accuracy: 0.9748 - lr: 2.0000e-05\n","Epoch 13/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9815"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 283ms/step - loss: 0.0352 - accuracy: 0.9815 - lr: 2.0000e-05\n","Epoch 14/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9866"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 285ms/step - loss: 0.0227 - accuracy: 0.9866 - lr: 2.0000e-05\n","Epoch 15/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9782"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 284ms/step - loss: 0.0318 - accuracy: 0.9782 - lr: 2.0000e-05\n","Epoch 16/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9883"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 281ms/step - loss: 0.0285 - accuracy: 0.9883 - lr: 2.0000e-05\n","Epoch 17/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9866"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 284ms/step - loss: 0.0238 - accuracy: 0.9866 - lr: 2.0000e-05\n","Epoch 18/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9849"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 285ms/step - loss: 0.0252 - accuracy: 0.9849 - lr: 2.0000e-05\n","Epoch 19/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9815"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 287ms/step - loss: 0.0225 - accuracy: 0.9815 - lr: 2.0000e-05\n","Epoch 20/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9832"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 284ms/step - loss: 0.0227 - accuracy: 0.9832 - lr: 2.0000e-05\n","Epoch 21/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9849"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 286ms/step - loss: 0.0203 - accuracy: 0.9849 - lr: 2.0000e-05\n","Epoch 22/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9866"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 283ms/step - loss: 0.0201 - accuracy: 0.9866 - lr: 2.0000e-05\n","Epoch 23/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9799"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 286ms/step - loss: 0.0206 - accuracy: 0.9799 - lr: 2.0000e-05\n","Epoch 24/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9899"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 286ms/step - loss: 0.0176 - accuracy: 0.9899 - lr: 2.0000e-05\n","Epoch 25/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9815"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 285ms/step - loss: 0.0197 - accuracy: 0.9815 - lr: 2.0000e-05\n","Epoch 26/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9883"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 286ms/step - loss: 0.0173 - accuracy: 0.9883 - lr: 2.0000e-05\n","Epoch 27/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9832"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 283ms/step - loss: 0.0179 - accuracy: 0.9832 - lr: 2.0000e-05\n","Epoch 28/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9849"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 285ms/step - loss: 0.0160 - accuracy: 0.9849 - lr: 2.0000e-05\n","Epoch 29/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9883"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 280ms/step - loss: 0.0157 - accuracy: 0.9883 - lr: 2.0000e-05\n","Epoch 30/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9883"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 284ms/step - loss: 0.0156 - accuracy: 0.9883 - lr: 2.0000e-05\n","Epoch 31/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9832"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 286ms/step - loss: 0.0177 - accuracy: 0.9832 - lr: 2.0000e-05\n","Epoch 32/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9832"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 282ms/step - loss: 0.0174 - accuracy: 0.9832 - lr: 2.0000e-05\n","Epoch 33/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9883"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 285ms/step - loss: 0.0168 - accuracy: 0.9883 - lr: 2.0000e-05\n","Epoch 34/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9866"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 283ms/step - loss: 0.0153 - accuracy: 0.9866 - lr: 2.0000e-05\n","Epoch 35/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9899"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 286ms/step - loss: 0.0169 - accuracy: 0.9899 - lr: 2.0000e-05\n","Epoch 36/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9866"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 281ms/step - loss: 0.0169 - accuracy: 0.9866 - lr: 2.0000e-05\n","Epoch 37/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9883"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 283ms/step - loss: 0.0158 - accuracy: 0.9883 - lr: 2.0000e-05\n","Epoch 38/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9866"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 283ms/step - loss: 0.0161 - accuracy: 0.9866 - lr: 2.0000e-05\n","Epoch 39/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9883"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 282ms/step - loss: 0.0154 - accuracy: 0.9883 - lr: 2.0000e-05\n","Epoch 40/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9883"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 285ms/step - loss: 0.0141 - accuracy: 0.9883 - lr: 2.0000e-05\n","Epoch 41/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9849"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 283ms/step - loss: 0.0155 - accuracy: 0.9849 - lr: 2.0000e-05\n","Epoch 42/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9916"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 284ms/step - loss: 0.0140 - accuracy: 0.9916 - lr: 2.0000e-05\n","Epoch 43/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9866"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 284ms/step - loss: 0.0162 - accuracy: 0.9866 - lr: 2.0000e-05\n","Epoch 44/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9849"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 284ms/step - loss: 0.0156 - accuracy: 0.9849 - lr: 2.0000e-05\n","Epoch 45/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9849"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 283ms/step - loss: 0.0164 - accuracy: 0.9849 - lr: 2.0000e-05\n","Epoch 46/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9899"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 285ms/step - loss: 0.0150 - accuracy: 0.9899 - lr: 2.0000e-05\n","Epoch 47/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9849"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 6s 287ms/step - loss: 0.0159 - accuracy: 0.9849 - lr: 2.0000e-05\n","Epoch 48/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9899"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 286ms/step - loss: 0.0148 - accuracy: 0.9899 - lr: 2.0000e-05\n","Epoch 49/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9899"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 6s 288ms/step - loss: 0.0142 - accuracy: 0.9899 - lr: 2.0000e-05\n","Epoch 50/50\n","19/19 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9883"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/19 [==============================] - 5s 285ms/step - loss: 0.0149 - accuracy: 0.9883 - lr: 2.0000e-05\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as bert_tokenizer_layer_call_fn, bert_tokenizer_layer_call_and_return_conditional_losses, multi_segment_packer_layer_call_fn, multi_segment_packer_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 316). These functions will not be directly callable after loading.\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f29ac32ad60>"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["# 3. 성능 평가"],"metadata":{"id":"Qd5TmGJwGDyj"}},{"cell_type":"code","source":["model = clf.tuner.get_best_models(num_models=1)[0]"],"metadata":{"id":"KTn0i-wljSRI","executionInfo":{"status":"ok","timestamp":1677984986194,"user_tz":-540,"elapsed":13190,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["print(type(model))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k3UrUl2wlNob","executionInfo":{"status":"ok","timestamp":1677984986194,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"1e26fe0b-fe6d-4259-e574-fb9140dd73e3"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'keras.engine.functional.Functional'>\n"]}]},{"cell_type":"code","source":["model.save(model_dir+\"model_autokeras_trial6_1_230305.h5\")"],"metadata":{"id":"UjejXtzPlYjc","executionInfo":{"status":"ok","timestamp":1677984988880,"user_tz":-540,"elapsed":2689,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["ak.CUSTOM_OBJECTS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QLLUEJorglAM","executionInfo":{"status":"ok","timestamp":1677984988880,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"218c22a8-706c-4c55-a26a-517fffc83733"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'BertPreprocessor': keras_nlp.models.bert.bert_preprocessor.BertPreprocessor,\n"," 'BertBackbone': keras_nlp.models.bert.bert_backbone.BertBackbone,\n"," 'CastToFloat32': autokeras.keras_layers.CastToFloat32,\n"," 'ExpandLastDim': autokeras.keras_layers.ExpandLastDim,\n"," 'MultiCategoryEncoding': autokeras.keras_layers.MultiCategoryEncoding}"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# model_to_use = predictor.get_model_best()\n","model_pred = clf.predict(test_text.values)"],"metadata":{"id":"FAJ3DmvA-khN","executionInfo":{"status":"ok","timestamp":1677985020983,"user_tz":-540,"elapsed":32114,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6d77fbe-a916-4465-f23b-cd3801d588d6"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["8/8 [==============================] - 6s 200ms/step\n","8/8 [==============================] - 2s 200ms/step\n"]}]},{"cell_type":"code","source":["submission['Category'] = model_pred"],"metadata":{"id":"RgHpQGX-Fpil","executionInfo":{"status":"ok","timestamp":1677985020984,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["submission = submission.astype({'Category':'int64'})"],"metadata":{"id":"mV773fieYcxO","executionInfo":{"status":"ok","timestamp":1677985020984,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["submission"],"metadata":{"id":"4nDZICszWOSV","executionInfo":{"status":"ok","timestamp":1677985020984,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"a5a62305-2e2b-4169-d47d-3c99d1e271a9"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Id  Category\n","0    710         1\n","1    487         0\n","2    136         1\n","3     44         1\n","4    627         0\n","..   ...       ...\n","244  702         1\n","245  500         0\n","246  818         0\n","247  584         0\n","248  355         0\n","\n","[249 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-29bbb5fb-50e4-41fe-815c-a46bc5be0a37\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>710</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>487</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>136</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>44</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>627</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>244</th>\n","      <td>702</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>245</th>\n","      <td>500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>246</th>\n","      <td>818</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>247</th>\n","      <td>584</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>248</th>\n","      <td>355</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>249 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29bbb5fb-50e4-41fe-815c-a46bc5be0a37')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-29bbb5fb-50e4-41fe-815c-a46bc5be0a37 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-29bbb5fb-50e4-41fe-815c-a46bc5be0a37');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["submission.to_csv(PATH+'submit/autokeras_text_val_acc_trial6_submission_230305.csv', index=False)"],"metadata":{"id":"X96PZVyRFpfu","executionInfo":{"status":"ok","timestamp":1677985020985,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["export_model = clf.export_model()\n","\n","try:\n","    export_model.save(model_dir+\"model_autokeras_trial6_230305\", save_format=\"tf\")\n","except Exception:\n","    export_model.save(model_dir+\"model_autokeras_trial6_230305.h5\")"],"metadata":{"id":"G-k-enJKjOeK","executionInfo":{"status":"ok","timestamp":1677985108367,"user_tz":-540,"elapsed":87387,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0cc6e730-e055-4b3d-80b6-65a789a8db11"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, bert_tokenizer_layer_call_fn, bert_tokenizer_layer_call_and_return_conditional_losses, multi_segment_packer_2_layer_call_fn, multi_segment_packer_2_layer_call_and_return_conditional_losses while saving (showing 5 of 317). These functions will not be directly callable after loading.\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report"],"metadata":{"id":"lYKhNeivXQV4","executionInfo":{"status":"ok","timestamp":1677985108368,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# Predict with the best model.\n","predicted_y = clf.predict(X_test.values)\n","# Evaluate the best model with testing data."],"metadata":{"id":"GM8diYWXCEyR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677985893190,"user_tz":-540,"elapsed":32308,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"3594fc3c-07dc-406d-c194-8d28a70e209b"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["5/5 [==============================] - 5s 223ms/step\n","5/5 [==============================] - 1s 218ms/step\n"]}]},{"cell_type":"code","source":["print(classification_report(y_test.values, predicted_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7C0GzmAemUjw","executionInfo":{"status":"ok","timestamp":1677985893191,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hyeonseo Yun","userId":"07510240751232710113"}},"outputId":"a3aed602-3b51-4641-a8f8-5c6125875010"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.90      0.93       104\n","         1.0       0.80      0.89      0.85        46\n","\n","    accuracy                           0.90       150\n","   macro avg       0.88      0.90      0.89       150\n","weighted avg       0.90      0.90      0.90       150\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"adGgdi_3GAbq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1DyAduAgP44M"},"execution_count":null,"outputs":[]}]}